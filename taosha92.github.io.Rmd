---
title: "taosha92.github.io"
author: "Sha Tao"
date: "November 11, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rvest)
library(httr)

theme_set(theme_bw())
```

## Problem 1_1 Data Loading

```{r p1_data_loading, message = FALSE}

read_csv_hw5 = function(x) {
  
  read_csv(x) %>% 
    mutate(name = x)

}

file_list = list.files("./data/") %>% paste0("./data/", .)

study = map_dfr(file_list, read_csv_hw5) %>% 
  mutate(arm = ifelse(str_detect(name, "con") == TRUE, "control", "experimental"),
         subject_id = substr(name, 12, 13)) %>% 
  gather(key = week, value = value, week_1:week_8) %>% 
  mutate(week = str_replace(week, "week_", ""),
         subject_id = as.factor(subject_id),
         week = as.integer(week)) %>% 
  select(subject_id, arm, week, value) %>% 
  arrange(subject_id, arm, week)

```

The dataset study after clean has `r ncol(study)` columns and `r nrow(study)` rows.\
This dataset contains two arms, each records 10 subjects across 8 weeks.

## Problem 1_2 Spaghetti Plots

```{r p1_spaghetti_plot, out.width = "100%"}

ggplot(study, aes(x = week, y = value, color = subject_id)) +
  geom_line() +
  facet_grid(.~ arm) +
  labs(
    title = "Value Change with Time in Control and Experimental Arms",
    x = "Week",
    y = "Value"
    )

```

The subjects in control arms started at the range of (0, 2.5), and ended up at approximately the same range at 8 week, while the subjects in experimental arms started at the range of (-0.5, 3.75), and ended up at the range of (3.5, 7).\
In other words, there is no apparent change of value with time in control arms, while there is increasing in experimental arm.

## Problem 2_1 Data Loading

```{r p2_data_loading}

p2_dataset = 
  RCurl::getURL("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>%
    read_csv()

```

## Problem 2_2 Data Cleaning

```{r p2_data_cleaning, warning = FALSE}

homicides =
  p2_dataset %>% 
  mutate(reported_year = as.integer(substr(reported_date, 1, 4)),
         reported_month = month.abb[as.integer(substr(reported_date, 5, 6))],
         reported_day = as.integer(substr(reported_date, 7, 8)),
         victim_race = as.factor(victim_race),
         victim_age = as.integer(victim_age),
         victim_sex = as.factor(victim_sex),
         city_state = paste(paste0(city, ","), state)) %>% 
  select(uid, reported_year, reported_month, reported_day, victim_last:victim_sex, city_state, lat:disposition)

```

## Problem 2_3 Data Exploring

```{r p2_data_exploring}

homicides %>% 
  select(uid, reported_year, reported_month, reported_day, victim_race, victim_age, victim_sex, city_state,
         lat, lon, disposition) %>% 
  skimr::skim()

```

The dataset homicides contains `r nrow(study)` observations.\
There are 2999 missing observations in victim_age, and 60 missing observations in latitude and longitude each.\ 
The mean victim age is 31.8 while median is 28.\
Black victims number (33361) is unproportionally larger than all the other race combined.\
There were 40739 male victims, and 7209 female victims in total.

## Problem 2_4 Count Homicides

```{r p2_count_homicides}

total_homicides = 
  homicides %>%
  group_by(city_state) %>% 
  summarize(total_n = n())

unsolved_homicides = 
  homicides %>% 
  filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") %>% 
  group_by(city_state) %>% 
  summarize(unsolved_n = n())

# join total_homicides and unsolved_homicides into one dataframe
count_homicides =
  inner_join(total_homicides, unsolved_homicides, by = "city_state")

```

## Problem 2_5 Baltimore, MD

```{r p2_baltimore}

# filter Baltimore  
baltimore_homicides = 
  count_homicides %>% 
  filter(city_state == "Baltimore, MD")

# compute the Baltimore proportion test
baltimore_prop = 
  prop.test(baltimore_homicides$unsolved_n, baltimore_homicides$total_n)

# save baltimore_prop as an object
save(baltimore_prop, file = "Baltimore_prop_test.RData")

# broom tidy, select only parameter estimate, and 95% CI
baltimore_prop =
  baltimore_prop %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)

# Display Baltimore proportion test table
baltimore_prop %>% 
  knitr::kable()

```

## Problem 2_6 All City

```{r p2_all_city}

# create function for all city proportion test
allcity_prop_test = function(x){
  
  city_homicides = 
    count_homicides %>% 
    filter(city_state == x)
  
  prop.test(city_homicides$unsolved_n, city_homicides$total_n) %>% 
    broom::tidy() %>% 
    select(estimate, conf.low, conf.high)
}

# compute city proportion test
city_prop = 
  tibble(city_state = count_homicides$city_state) %>% 
  mutate(map(.x = count_homicides$city_state, ~allcity_prop_test(.x))) %>% 
  unnest

```

## Problem 2_7 Proportion and 95% CI Plot

```{r p2_proportion_plot, out.width = "100%"}

city_prop %>% 
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
    geom_point() +
    geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.3, size = 7)) +
    labs(
      x = "City",
      y = "Proportion",
      title = "Proportion of unsolved cases for cities"
    )

```

Chicago, New Orleans and Baltimore had the three highest proportion of parameter estimates while had a relatively small 95% confidence interval.\
Among them, Chigago had significantly higher proportion than the others.\
Richmond, Charlotte and Memphis had the three lowest proportion of parameter estimates.

